{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a76f018",
   "metadata": {},
   "source": [
    "# Search engine with Tools and Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c3a669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arxiv --Research\n",
    "## Tools Creation\n",
    "## ArxivqueryRun,WikipediaQueryRun is needed to interact with both the sites outside of langchain to run a user query\n",
    "## ArxivAPIWrapper,WikipediaAPIWrapper is needed to allow the third party data source access from langchain framework\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper,WikipediaAPIWrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "960fc56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Used the in-built tool of wikipedia \n",
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results = 1,doc_content_chars_max=250)\n",
    "wiki = WikipediaQueryRun(api_wrapper = api_wrapper_wiki)\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f13f4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Used in-built Arxiv Tool\n",
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
    "arxiv = ArxivQueryRun(api_wrapper = api_wrapper_arxiv) \n",
    "arxiv.name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb7742ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## our in-built tools\n",
    "tools = [wiki,arxiv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a363e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating our custom tools [RAG Tools]\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model= \"jason1234/arzington_bert_embedding_model_v6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "920aeede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000191CF9000A0>, search_kwargs={})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(web_path = \"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "splits= RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap=100).split_documents(documents=docs)\n",
    "vectordb = FAISS.from_documents(splits,embeddings)\n",
    "retriever = vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cf194b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith-search'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating retriever Tool\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(retriever,\"langsmith-search\",\"Search engine tool\")\n",
    "retriever_tool.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "853b4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[arxiv,wiki,retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7497e6de",
   "metadata": {},
   "source": [
    "## Run all these Tools & LLMs using Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d025b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Groq for LLM model here\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import OpenAI\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(model_name = \"llama3-70b-8192\", groq_api_key = groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c854fc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Alternative way to create prompt by importing a prompt template defined on Hub\n",
    "\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d929457f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000191DB534430>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000191DB534430>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000191CF8276A0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000191CF845C60>, model_name='llama3-70b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith-search', 'description': 'Search engine tool', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating Tools Agent to utilise our list of tools[wiki,arxiv,retriever_tool] that we have created earlier\n",
    "## It will query the data source provided in web path but if query is from outside of that \n",
    "# then it will make use of apt tool that we ahve created\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm,tools,prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e6524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'creating agents using openai'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: ChatGPT\n",
      "Summary: ChatGPT is a generative artificial intelligence chatbot developed by OpenAI and released on November 30, 2022. It uses large language models (LLMs) such as GPT-4o along with other multimodal models to generate human-like respon\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith-search` with `{'query': 'creating agents using openai'}`\n",
      "responded: It seems like the Wikipedia tool provided some information about ChatGPT, but it doesn't directly answer your question about creating agents using OpenAI. Let me try to help you further.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mGet started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\n",
      "\n",
      "Get started by creating your first prompt.\n",
      "Iterate on models and prompts using the Playground.\n",
      "Manage prompts programmatically in your application.\n",
      "Was this page helpful?You can leave detailed feedback on GitHub.NextQuick StartObservabilityEvalsPrompt EngineeringCommunityTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.\n",
      "\n",
      "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
      "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
      "Observability​\u001b[0m\u001b[32;1m\u001b[1;3mIt seems that the tool call yielded information about LangSmith, a platform for building ambient agents. To provide a more direct answer to your original question, I'll respond without using a tool.\n",
      "\n",
      "Creating agents using OpenAI typically involves using their APIs and models to develop conversational AI systems. OpenAI provides various tools and resources, such as the OpenAI API, LangChain, and LangGraph, to help developers build and customize their agents.\n",
      "\n",
      "To get started, you can explore OpenAI's documentation and guides, which provide information on how to use their APIs, models, and frameworks to create agents. You can also experiment with their playgrounds and tutorials to gain hands-on experience.\n",
      "\n",
      "Additionally, you can leverage OpenAI's pre-trained models, such as ChatGPT, to develop more advanced agents that can understand and respond to user input in a more human-like way.\n",
      "\n",
      "If you have more specific questions or need further guidance on creating agents using OpenAI, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about creating agents using openai.',\n",
       " 'output': \"It seems that the tool call yielded information about LangSmith, a platform for building ambient agents. To provide a more direct answer to your original question, I'll respond without using a tool.\\n\\nCreating agents using OpenAI typically involves using their APIs and models to develop conversational AI systems. OpenAI provides various tools and resources, such as the OpenAI API, LangChain, and LangGraph, to help developers build and customize their agents.\\n\\nTo get started, you can explore OpenAI's documentation and guides, which provide information on how to use their APIs, models, and frameworks to create agents. You can also experiment with their playgrounds and tutorials to gain hands-on experience.\\n\\nAdditionally, you can leverage OpenAI's pre-trained models, such as ChatGPT, to develop more advanced agents that can understand and respond to user input in a more human-like way.\\n\\nIf you have more specific questions or need further guidance on creating agents using OpenAI, feel free to ask!\"}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Executing Tools Agent\n",
    "## It will call the tools[wiki,arxiv] if LLM is not capable of answering the query using given data surce here which is LangSmith website\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor= AgentExecutor(agent=agent, tools=tools,verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\" : \"Tell me about creating agents using openai.\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c2594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
